# Glossary: Course 6, Modules 1 & 2

---

## A

**Accuracy**  
Proportion of data points that were correctly categorized.

---

## B

**Bayes’ Theorem**  
An equation used to calculate the probability of an outcome or class, given the values of predictor variables.

---

## C

**Categorical variables**  
Variables that contain a finite number of groups or categories.

**Class imbalance**  
Occurs when a dataset has more instances of one outcome than another.

**Collaborative filtering**  
A technique used by recommendation systems to make comparisons based on who else liked the content.

**Content-based filtering**  
A recommendation method based on item attributes rather than user behavior.

**Continuous variables**  
Variables that can take on an infinite and uncountable set of values.

**Customer churn**  
The rate at which customers stop using a product, service, or company.

---

## D

**Decision tree**  
A flowchart-like structure that uses branches to predict outcomes or probabilities.

**Discrete features**  
Features with a countable number of values between any two points.

**Documentation**  
Detailed information about a software package, written by its developers.

**Downsampling**  
The process of reducing the majority class size in an imbalanced dataset.

---

## F

**F1-Score**  
The harmonic mean of precision and recall.

**Feature engineering**  
Using domain and statistical knowledge to select, transform, or extract features from raw data.

**Feature extraction**  
Creating new features from existing ones to improve model accuracy.

**Feature selection**  
Choosing the most predictive features in the dataset.

**Feature transformation**  
Modifying features to improve model training and accuracy.

---

## I

**Integrated Development Environment (IDE)**  
Software for writing, running, and testing code in one place.

---

## M

**Machine learning**  
Using algorithms and statistical models to teach computers to analyze and find patterns in data.

---

## N

**Naive Bayes**  
A supervised classification model based on Bayes’ Theorem that assumes predictors are independent.

---

## P

**Plan stage**  
PACE stage where the project scope and informational needs are defined.

**Popularity bias**  
When frequently used or liked items are recommended more often, even excessively.

**Posterior probability**  
The probability of an event after considering new information.

**Precision**  
The proportion of correct positive predictions out of all positive predictions.

---

## R

**Recall**  
The proportion of actual positives that were correctly identified.

**Recommendation systems**  
Unsupervised learning systems that suggest content based on data patterns.

---

## S

**Supervised model**  
A model trained with labeled data to predict outcomes.

**Supervised machine learning**  
Machine learning that uses labeled data for classification or prediction.

---

## U

**Unsupervised model**  
Used to explore data and find hidden structures without labeled outputs.

**Upsampling**  
Increasing the size of the minority class by duplicating or generating new data points.

---

## Z

**“Zero Frequency” problem**  
Occurs when a class label and predictor value never appear together, causing zero probability.